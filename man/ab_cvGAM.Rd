% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ab_cvGAM.R
\name{ab_cvGAM}
\alias{ab_cvGAM}
\title{Select optimal degrees of freedom for SL.gam() using cross-validation}
\usage{
ab_cvGAM(Y, X, id = NULL, family = gaussian(), SL.library, print = FALSE,
  df = 2:10)
}
\arguments{
\item{Y}{The outcome. Must be a numeric vector.}

\item{X}{A matrix of features that predict Y, usually a data.frame.}

\item{id}{An optional cluster or repeated measures id variable. For cross-validation splits, \code{id} forces observations in the same cluster or for the same individual to be in the same validation fold.}

\item{family}{Model family (gaussian for continuous outcomes, binomial for binary outcomes)}

\item{SL.library}{SuperLearner library}

\item{print}{logical. print messages? Defaults to FALSE}

\item{df}{a sequence of degrees of freedom to control the smoothness of natural splines in the GAM model. Defaults to 2:6}
}
\value{
returns a list with updated SuperLearner library, the optimal node size, and cvRisks
}
\description{
ab_cvGAM is an internal tuning function called by \code{agecurveAb} and \code{tmleAb} that selects degrees of freedom for natural splines in a GAM model using cross-validation
}
\details{
\code{ab_cvGAM} is an internal function called by \code{\link[tmleAb]{agecurveAb}} or \code{tmleAb} if SL.gam() is included in the algorithm library. It performs an addition pre-screen step of selecting the optimal spline degress of freedom using cross validation. The default is to search over degrees 2,3,...10, which is usually pretty good. This additional selection step enables you to tune the smoothing parameter. Cross-validated risks are estimated using \code{\link[SuperLearner]{SuperLearner}}.
}
\examples{
TBD
}

